============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
wandb: Appending key for api.wandb.ai to your netrc file: /home/overven/.netrc
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: sheep_${code_version}/${group_name}
  scenario: sheep
  env:
    name: sheep_baseline_concurrent_systemic
    class_name: sheep_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: true
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: false
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Systemic_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 1
debug: false

Selected template class: Llama3Chat
[2025-01-26 19:22:49,265][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:06<00:18,  6.11s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:11<00:11,  5.93s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:17<00:05,  5.77s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.05s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.73s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_192310-uvgarxtm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-armadillo-447
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/uvgarxtm
Storage name: valiant-armadillo-447-uvgarxtm
[2025-01-26 19:23:18,109][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 19:23:20,414][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in  N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in  N/A

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim_v2/simulation/results/sheep_v6.4/Systemic_Meta-Llama-3-8B-Instruct/valiant-armadillo-447/.hydra)... Done. 0.0s
wandb: - 0.028 MB of 0.028 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: \ 0.028 MB of 0.028 MB uploadedwandb: | 0.028 MB of 0.069 MB uploadedwandb: / 0.069 MB of 0.069 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–â–â–â–â–…â–†â–…â–†â–†â–ˆâ–‡â–‡â–…â–ƒâ–„â–†â–‡â–†â–†â–‡â–…â–…â–†â–…â–†
wandb:       experiment/TFS_cumulative â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–
wandb:    persona_1_collected_resource â–
wandb:    persona_2_collected_resource â–
wandb:    persona_3_collected_resource â–
wandb:    persona_4_collected_resource â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 769.19115
wandb:       experiment/TFS_cumulative 558.75462
wandb:  experiment/token_in_cumulative 70856
wandb: experiment/token_out_cumulative 3769
wandb:                    num_resource 0
wandb:    persona_0_collected_resource 15
wandb:    persona_1_collected_resource 80
wandb:    persona_2_collected_resource 70
wandb:    persona_3_collected_resource 20
wandb:    persona_4_collected_resource 70
wandb: 
wandb: ðŸš€ View run valiant-armadillo-447 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/uvgarxtm
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_192310-uvgarxtm/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: sheep_${code_version}/${group_name}
  scenario: sheep
  env:
    name: sheep_baseline_concurrent_systemic
    class_name: sheep_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: true
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: false
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Systemic_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 42
debug: false

Selected template class: Llama3Chat
[2025-01-26 19:25:44,496][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.25s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.28s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.59s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.84s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_192553-87jr8va3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-valley-449
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/87jr8va3
Storage name: dry-valley-449-87jr8va3
[2025-01-26 19:26:01,613][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 19:26:03,292][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in  N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in  N/A

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim_v2/simulation/results/sheep_v6.4/Systemic_Meta-Llama-3-8B-Instruct/dry-valley-449/.hydra)... Done. 0.0s
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–â–‚â–â–â–†â–†â–„â–‡â–…â–ˆâ–†â–ƒâ–ƒâ–†â–†â–…â–†â–†â–‡â–…â–†â–†â–…
wandb:       experiment/TFS_cumulative â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–
wandb:    persona_1_collected_resource â–
wandb:    persona_2_collected_resource â–
wandb:    persona_3_collected_resource â–
wandb:    persona_4_collected_resource â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 741.51751
wandb:       experiment/TFS_cumulative 472.70217
wandb:  experiment/token_in_cumulative 56561
wandb: experiment/token_out_cumulative 3753
wandb:                    num_resource 0
wandb:    persona_0_collected_resource 70
wandb:    persona_1_collected_resource 80
wandb:    persona_2_collected_resource 70
wandb:    persona_3_collected_resource 90
wandb:    persona_4_collected_resource 50
wandb: 
wandb: ðŸš€ View run dry-valley-449 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/87jr8va3
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_192553-87jr8va3/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: sheep_${code_version}/${group_name}
  scenario: sheep
  env:
    name: sheep_baseline_concurrent_systemic
    class_name: sheep_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: true
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: false
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Systemic_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 100
debug: false

Selected template class: Llama3Chat
[2025-01-26 19:28:25,120][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.25s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.27s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.59s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.83s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_192834-njd2d5em
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-puddle-452
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/njd2d5em
Storage name: cool-puddle-452-njd2d5em
[2025-01-26 19:28:42,173][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 19:28:44,347][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in  N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in  N/A

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim_v2/simulation/results/sheep_v6.4/Systemic_Meta-Llama-3-8B-Instruct/cool-puddle-452/.hydra)... Done. 0.4s
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–‚â–â–â–â–…â–…â–„â–…â–…â–†â–†â–†â–†â–ƒâ–„â–†â–…â–…â–…â–…â–„â–„â–ˆâ–„â–„
wandb:       experiment/TFS_cumulative â–â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    num_resource â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–
wandb:    persona_1_collected_resource â–
wandb:    persona_2_collected_resource â–
wandb:    persona_3_collected_resource â–
wandb:    persona_4_collected_resource â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 573.92547
wandb:       experiment/TFS_cumulative 532.83984
wandb:  experiment/token_in_cumulative 68491
wandb: experiment/token_out_cumulative 3792
wandb:                    num_resource 0
wandb:    persona_0_collected_resource 15
wandb:    persona_1_collected_resource 80
wandb:    persona_2_collected_resource 70
wandb:    persona_3_collected_resource 20
wandb:    persona_4_collected_resource 50
wandb: 
wandb: ðŸš€ View run cool-puddle-452 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/njd2d5em
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_192834-njd2d5em/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: sheep_${code_version}/${group_name}
  scenario: sheep
  env:
    name: sheep_baseline_concurrent_systemic
    class_name: sheep_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: true
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: false
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Systemic_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 150
debug: false

Selected template class: Llama3Chat
[2025-01-26 19:31:12,204][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.24s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.28s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.60s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.84s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_193121-auwmiddq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-cosmos-455
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/auwmiddq
Storage name: lemon-cosmos-455-auwmiddq
[2025-01-26 19:31:29,578][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 19:31:31,115][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in  N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in  N/A

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim_v2/simulation/results/sheep_v6.4/Systemic_Meta-Llama-3-8B-Instruct/lemon-cosmos-455/.hydra)... Done. 0.0s
wandb: - 0.028 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb: | 0.028 MB of 0.028 MB uploadedwandb: / 0.028 MB of 0.028 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: - 0.028 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–‚â–‚â–â–â–…â–…â–„â–†â–…â–†â–†â–ˆâ–ˆâ–ƒâ–„â–‡â–‡â–‡â–‡â–‡â–…â–…â–†â–…â–…
wandb:       experiment/TFS_cumulative â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                    num_resource â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–
wandb:    persona_1_collected_resource â–
wandb:    persona_2_collected_resource â–
wandb:    persona_3_collected_resource â–
wandb:    persona_4_collected_resource â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 646.49978
wandb:       experiment/TFS_cumulative 527.63926
wandb:  experiment/token_in_cumulative 71896
wandb: experiment/token_out_cumulative 4067
wandb:                    num_resource 0
wandb:    persona_0_collected_resource 70
wandb:    persona_1_collected_resource 80
wandb:    persona_2_collected_resource 70
wandb:    persona_3_collected_resource 20
wandb:    persona_4_collected_resource 50
wandb: 
wandb: ðŸš€ View run lemon-cosmos-455 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/auwmiddq
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_193121-auwmiddq/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: sheep_${code_version}/${group_name}
  scenario: sheep
  env:
    name: sheep_baseline_concurrent_systemic
    class_name: sheep_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: true
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: false
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Systemic_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 200
debug: false

Selected template class: Llama3Chat
[2025-01-26 19:34:09,821][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.25s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.27s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.24s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.59s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.83s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_193418-ujjqqauc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-morning-458
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/ujjqqauc
Storage name: avid-morning-458-ujjqqauc
[2025-01-26 19:34:26,965][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 19:34:29,106][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in  N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in  N/A

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim_v2/simulation/results/sheep_v6.4/Systemic_Meta-Llama-3-8B-Instruct/avid-morning-458/.hydra)... Done. 0.0s
wandb: - 0.028 MB of 0.028 MB uploadedwandb: \ 0.028 MB of 0.028 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: | 0.028 MB of 0.028 MB uploadedwandb: / 0.028 MB of 0.028 MB uploadedwandb: - 0.028 MB of 0.028 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–â–â–â–â–‡â–…â–…â–…â–†â–…â–‡â–ˆâ–ˆâ–„â–„â–…â–‡â–…â–†â–†â–…â–„â–…â–†â–…
wandb:       experiment/TFS_cumulative â–â–â–â–â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–
wandb:    persona_1_collected_resource â–
wandb:    persona_2_collected_resource â–
wandb:    persona_3_collected_resource â–
wandb:    persona_4_collected_resource â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 655.46062
wandb:       experiment/TFS_cumulative 541.57798
wandb:  experiment/token_in_cumulative 69903
wandb: experiment/token_out_cumulative 3865
wandb:                    num_resource 0
wandb:    persona_0_collected_resource 15
wandb:    persona_1_collected_resource 80
wandb:    persona_2_collected_resource 15
wandb:    persona_3_collected_resource 90
wandb:    persona_4_collected_resource 70
wandb: 
wandb: ðŸš€ View run avid-morning-458 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/ujjqqauc
wandb: Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_193418-ujjqqauc/logs

JOB STATISTICS
==============
Job ID: 9616278
Cluster: snellius
User/Group: overven/overven
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:26:02
CPU Efficiency: 10.01% of 04:20:06 core-walltime
Job Wall-clock time: 00:14:27
Memory Utilized: 2.74 GB
Memory Efficiency: 2.28% of 120.00 GB
