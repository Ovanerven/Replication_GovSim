============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
wandb: Appending key for api.wandb.ai to your netrc file: /home/overven/.netrc
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
/gpfs/home2/overven/GovSim/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: fishing_${code_version}/${group_name}
  scenario: fishing
  env:
    name: fish_baseline_concurrent
    class_name: fishing_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Meta-Llama-2-13B
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 1
debug: false

[2025-01-19 23:46:52,890][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:23, 11.67s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  5.65s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.04s/it]
[2025-01-19 23:47:14,162][accelerate.big_modeling][WARNING] - Some parameters are on the meta device because they were offloaded to the cpu.
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim/wandb/run-20250119_234718-5gmnmhy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-voice-50
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/5gmnmhy9
Storage name: absurd-voice-50-5gmnmhy9
[2025-01-19 23:47:27,818][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
/home/overven/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-01-19 23:47:30,931][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim/simulation/results/fishing_v6.4/Meta-Llama-2-13B/absurd-voice-50/.hydra)... Done. 0.0s
wandb: - 0.015 MB of 0.015 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.039 MB uploadedwandb: / 0.077 MB of 0.077 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–â–ƒâ–‡â–â–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒ
wandb:       experiment/TFS_cumulative â–â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  experiment/token_in_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_1_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_2_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_3_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_4_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 171.41507
wandb:       experiment/TFS_cumulative 267.05129
wandb:  experiment/token_in_cumulative 222792
wandb: experiment/token_out_cumulative 696
wandb:                    num_resource 100
wandb:    persona_0_collected_resource 0
wandb:    persona_1_collected_resource 0
wandb:    persona_2_collected_resource 0
wandb:    persona_3_collected_resource 0
wandb:    persona_4_collected_resource 0
wandb: 
wandb: ðŸš€ View run absurd-voice-50 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/5gmnmhy9
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250119_234718-5gmnmhy9/logs
/gpfs/home2/overven/GovSim/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: fishing_${code_version}/${group_name}
  scenario: fishing
  env:
    name: fish_baseline_concurrent
    class_name: fishing_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Meta-Llama-2-13B
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 42
debug: false

[2025-01-20 00:01:38,897][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:04<00:09,  4.51s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:03,  3.90s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.69s/it]
[2025-01-20 00:01:47,115][accelerate.big_modeling][WARNING] - Some parameters are on the meta device because they were offloaded to the cpu.
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim/wandb/run-20250120_000150-d9xhxwh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-frost-51
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/d9xhxwh7
Storage name: unique-frost-51-d9xhxwh7
[2025-01-20 00:01:59,131][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
/home/overven/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-01-20 00:02:00,645][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim/simulation/results/fishing_v6.4/Meta-Llama-2-13B/unique-frost-51/.hydra)... Done. 0.0s
wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: | 0.015 MB of 0.015 MB uploadedwandb: / 0.015 MB of 0.015 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–â–ƒâ–ˆâ–â–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒ
wandb:       experiment/TFS_cumulative â–â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  experiment/token_in_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_1_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_2_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_3_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_4_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 176.06964
wandb:       experiment/TFS_cumulative 273.05464
wandb:  experiment/token_in_cumulative 222792
wandb: experiment/token_out_cumulative 696
wandb:                    num_resource 100
wandb:    persona_0_collected_resource 0
wandb:    persona_1_collected_resource 0
wandb:    persona_2_collected_resource 0
wandb:    persona_3_collected_resource 0
wandb:    persona_4_collected_resource 0
wandb: 
wandb: ðŸš€ View run unique-frost-51 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/d9xhxwh7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250120_000150-d9xhxwh7/logs
/gpfs/home2/overven/GovSim/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: fishing_${code_version}/${group_name}
  scenario: fishing
  env:
    name: fish_baseline_concurrent
    class_name: fishing_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Meta-Llama-2-13B
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 100
debug: false

[2025-01-20 00:15:53,241][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:23, 11.59s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:15<00:06,  6.80s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:15<00:00,  5.04s/it]
[2025-01-20 00:16:08,504][accelerate.big_modeling][WARNING] - Some parameters are on the meta device because they were offloaded to the cpu.
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim/wandb/run-20250120_001611-5q8encuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-tree-52
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/5q8encuj
Storage name: happy-tree-52-5q8encuj
[2025-01-20 00:16:20,328][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
/home/overven/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-01-20 00:16:21,993][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(num_resource, 100, 0.0, 1.0, 1.0, \d+, None) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim/simulation/results/fishing_v6.4/Meta-Llama-2-13B/happy-tree-52/.hydra)... Done. 0.0s
wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: | 0.015 MB of 0.015 MB uploadedwandb: / 0.015 MB of 0.015 MB uploadedwandb: - 0.015 MB of 0.015 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–‡â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–â–ˆâ–â–ƒâ–ˆâ–â–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒ
wandb:       experiment/TFS_cumulative â–â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  experiment/token_in_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_1_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_2_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_3_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_4_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 176.32871
wandb:       experiment/TFS_cumulative 271.77739
wandb:  experiment/token_in_cumulative 222792
wandb: experiment/token_out_cumulative 696
wandb:                    num_resource 100
wandb:    persona_0_collected_resource 0
wandb:    persona_1_collected_resource 0
wandb:    persona_2_collected_resource 0
wandb:    persona_3_collected_resource 0
wandb:    persona_4_collected_resource 0
wandb: 
wandb: ðŸš€ View run happy-tree-52 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/5q8encuj
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250120_001611-5q8encuj/logs
/gpfs/home2/overven/GovSim/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Meta-Llama-2-13B
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 1
debug: false

[2025-01-20 00:30:18,166][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:04<00:08,  4.47s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:03,  3.86s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.66s/it]
[2025-01-20 00:30:26,306][accelerate.big_modeling][WARNING] - Some parameters are on the meta device because they were offloaded to the cpu.
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim/wandb/run-20250120_003029-9i1r1d0q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-cherry-54
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/9i1r1d0q
Storage name: ancient-cherry-54-9i1r1d0q
[2025-01-20 00:30:38,475][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
/home/overven/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-01-20 00:30:40,690][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 125, in _get_gen
    generation_config = GenerationConfig.from_pretrained(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 877, in from_pretrained
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/utils/hub.py", line 370, in cached_file
    raise EnvironmentError(
OSError: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8 does not appear to have a file named generation_config.json. Checkout 'https://huggingface.co//gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8/tree/main' for available files.

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 221.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 440.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 237, in _get_find
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 221.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 440.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 207.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 287.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 237, in _get_find
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 207.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 287.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 176.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 237, in _get_find
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 176.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 140.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 237, in _get_find
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 140.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 111.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 392.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 111.88 MiB is free. Process 2753104 has 16.69 GiB memory in use. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 392.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 654.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 654.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 537.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 537.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 612.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 612.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 271.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 606.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 271.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 606.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 589.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Process 2753104 has 16.72 GiB memory in use. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 589.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 229.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 249.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 229.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 249.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 303.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 246.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 303.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 246.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 307.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 243.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 307.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 243.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 277.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 600.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 277.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 600.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 93.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 459.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 93.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 459.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 576.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 576.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 630.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 630.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 307.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 570.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 307.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 570.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 147.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 477.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 147.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 477.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 93.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 532.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 93.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 532.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 462.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 462.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 295.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 292.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 295.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 292.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 289.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 289.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 123.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 380.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 123.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 380.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 255.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 255.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 281.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 156.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 281.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 156.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.72 GiB is allocated by PyTorch, and 403.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.72 GiB is allocated by PyTorch, and 403.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 157.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 241.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 157.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 241.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 231.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 393.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 231.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 393.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 333.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 333.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 589.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 589.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.61 GiB is allocated by PyTorch, and 655.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.61 GiB is allocated by PyTorch, and 655.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 471.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 471.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 313.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 313.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 231.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 433.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 231.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 433.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 209.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 269.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 209.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 269.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 299.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 238.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 299.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 238.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 241.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 361.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 241.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 361.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 277.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 323.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 277.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 323.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 99.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.90 GiB is allocated by PyTorch, and 369.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 99.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.90 GiB is allocated by PyTorch, and 369.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 91.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 319.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 91.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 319.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 125.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 275.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 125.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 275.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 305.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 305.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A (No specific production limit was agreed upon.): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A (No specific production limit was agreed upon.)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 233.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 644.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 233.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 644.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 446.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 446.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 211.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 382.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 211.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 382.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 159.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 319.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 159.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 319.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 305.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 206.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 305.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 206.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 201.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 277.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 201.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 277.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 372.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 372.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 350.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 350.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 183.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 183.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 193.88 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 193.88 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 219.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Of the allocated memory 18.98 GiB is allocated by PyTorch, and 166.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 219.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Of the allocated memory 18.98 GiB is allocated by PyTorch, and 166.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 261.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 233.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 261.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 233.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 295.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 582.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 295.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 582.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 119.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 503.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 119.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 503.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 165.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.69 GiB is allocated by PyTorch, and 524.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 165.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.69 GiB is allocated by PyTorch, and 524.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 289.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 289.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 441.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 441.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 198.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 198.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 175.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 275.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 175.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 97.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 416.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 97.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 416.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 197.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 197.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 251.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 163.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 251.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 163.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.53 GiB is allocated by PyTorch, and 717.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.53 GiB is allocated by PyTorch, and 717.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.61 GiB is allocated by PyTorch, and 643.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.61 GiB is allocated by PyTorch, and 643.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 543.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 543.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.68 GiB is allocated by PyTorch, and 585.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.68 GiB is allocated by PyTorch, and 585.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 143.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.70 GiB is allocated by PyTorch, and 536.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 143.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.70 GiB is allocated by PyTorch, and 536.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 245.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 632.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 245.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 632.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 628.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 249.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 628.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 590.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 285.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 590.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 149.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 555.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 149.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 555.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 147.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 440.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 147.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 440.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 137.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 341.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 137.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 341.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 151.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 327.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 151.88 MiB is free. Including non-PyTorch memory, this process has 19.43 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 327.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 287.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 590.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 287.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 590.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 243.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 634.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 243.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 634.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 654.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 223.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 654.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 293.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 584.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 293.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 584.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 163.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.72 GiB is allocated by PyTorch, and 493.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 163.88 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.72 GiB is allocated by PyTorch, and 493.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 305.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 572.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 305.88 MiB is free. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 572.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 121.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.62 GiB is allocated by PyTorch, and 636.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 121.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.62 GiB is allocated by PyTorch, and 636.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 141.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 596.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 141.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 596.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 221.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 656.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 221.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 656.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 233.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 644.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 233.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 644.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 594.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 241.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 241.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 591.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 591.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 95.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.59 GiB is allocated by PyTorch, and 692.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 95.88 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.59 GiB is allocated by PyTorch, and 692.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 504.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 504.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 379.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 379.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 73.88 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 501.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 73.88 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 501.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 111.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 429.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 111.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 429.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 209.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 214.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 209.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 214.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 135.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 412.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 135.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 412.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 121.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 631.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 121.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 631.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 141.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 591.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 141.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 591.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 129.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.57 GiB is allocated by PyTorch, and 683.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 129.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.57 GiB is allocated by PyTorch, and 683.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 612.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 612.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 287.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 257.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 287.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 257.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.68 GiB is allocated by PyTorch, and 446.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.68 GiB is allocated by PyTorch, and 446.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 323.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 265.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 323.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 173.88 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 305.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 173.88 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 305.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 376.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 127.88 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 376.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 135.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 409.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 135.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 409.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 137.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 362.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 137.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 362.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 191.88 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 406.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 191.88 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 406.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 436.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.80 GiB is allocated by PyTorch, and 436.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 207.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 257.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 207.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 257.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.53 GiB is allocated by PyTorch, and 717.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.53 GiB is allocated by PyTorch, and 717.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 139.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 611.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 139.88 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.63 GiB is allocated by PyTorch, and 611.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 227.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 650.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 235.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 642.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 235.88 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 642.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 243.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 243.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 241.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 374.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 241.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 374.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 260.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.86 GiB is allocated by PyTorch, and 260.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 363.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 115.88 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 363.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 452.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 283.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.64 GiB is allocated by PyTorch, and 452.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 326.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 326.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 105.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 430.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 105.88 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 430.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 276.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1164, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 968, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 727, in forward
    hidden_states = self.mlp(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 216, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
                                           ^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 133.88 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 276.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 276.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 276.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 269.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 608.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 254.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 301.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 254.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 91, in __add__
    raise Exception(
Exception: gen(option, 100, 0.0, 1.0, 1.0, \d+, tons) can be used only in assistant block, not in user block!

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 293.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 225.88 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 293.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 337.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 337.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 187.88 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 307.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 313.88 MiB is free. Including non-PyTorch memory, this process has 19.27 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 307.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 577.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.52 GiB is allocated by PyTorch, and 577.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 598.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 279.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 598.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 610.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 610.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 253.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 624.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 281.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 596.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 281.88 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 596.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 273.88 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 293.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 584.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 293.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 584.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 203.88 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 674.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
wandb: Adding directory to artifact (/gpfs/home2/overven/GovSim/simulation/results/pollution_v6.4/Meta-Llama-2-13B/ancient-cherry-54/.hydra)... Done. 0.0s
wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.015 MB uploadedwandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: / 0.015 MB of 0.015 MB uploadedwandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.015 MB uploadedwandb: 
wandb: Run history:
wandb:                  experiment/TFS â–â–ˆâ–â–â–ƒâ–â–‚â–â–‡â–â–â–‡â–â–â–â–â–‚â–â–â–‚â–â–‡â–â–â–â–â–â–â–â–‚â–â–‡â–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb:       experiment/TFS_cumulative â–â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  experiment/token_in_cumulative â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: experiment/token_out_cumulative â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                    num_resource â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_0_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_1_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_2_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_3_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    persona_4_collected_resource â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                  experiment/TFS 51.18273
wandb:       experiment/TFS_cumulative 32.33631
wandb:  experiment/token_in_cumulative 935907
wandb: experiment/token_out_cumulative 26868
wandb:                    num_resource 100
wandb:    persona_0_collected_resource 0
wandb:    persona_1_collected_resource 0
wandb:    persona_2_collected_resource 0
wandb:    persona_3_collected_resource 0
wandb:    persona_4_collected_resource 0
wandb: 
wandb: ðŸš€ View run ancient-cherry-54 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/9i1r1d0q
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250120_003029-9i1r1d0q/logs
/gpfs/home2/overven/GovSim/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Meta-Llama-3-8B
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/llama13B/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 42
debug: false

[2025-01-20 08:47:18,707][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:22, 11.43s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:06,  6.75s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:14<00:00,  5.00s/it]
[2025-01-20 08:47:33,849][accelerate.big_modeling][WARNING] - Some parameters are on the meta device because they were offloaded to the cpu.
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim/wandb/run-20250120_084738-hezzuklx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-pyramid-74
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/hezzuklx
Storage name: elated-pyramid-74-hezzuklx
[2025-01-20 08:47:49,777][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
/home/overven/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-01-20 08:47:52,232][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 334.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 237, in _get_find
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 291.88 MiB is free. Including non-PyTorch memory, this process has 19.29 GiB memory in use. Of the allocated memory 18.75 GiB is allocated by PyTorch, and 334.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in find
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 211.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 665.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 211.88 MiB is free. Including non-PyTorch memory, this process has 19.37 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 665.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 621.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 255.88 MiB is free. Including non-PyTorch memory, this process has 19.33 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 621.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 609.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 267.88 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 609.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:111: RuntimeWarning: An exception occured: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 629.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables): Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 101, in gen
    lm: Model = previous_lm + pathfinder.gen(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 96, in __add__
    res = lm._get_gen(value)
          ^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 157, in _get_gen
    output = self.model.generate(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 1736, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/generation/utils.py", line 2375, in _sample
    outputs = self(
              ^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 1183, in forward
    logits = self.lm_head(hidden_states)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.conda/envs/GovComGPTQ/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 165, in new_forward
    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/hooks.py", line 355, in pre_forward
    set_module_tensor_to_device(
  File "/home/overven/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 19.62 GiB of which 247.88 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Process 4023152 has 580.00 MiB memory in use. Of the allocated memory 18.50 GiB is allocated by PyTorch, and 629.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Returning default value in gen
  warnings.warn(
/gpfs/home2/overven/GovSim/simulation/utils/models.py:176: RuntimeWarning: An exception occured: Regex \d+ not found in N/A: Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim/simulation/utils/models.py", line 166, in find
    lm: Model = previous_lm + pathfinder.find(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/backend.py", line 99, in __add__
    res, original_res = lm._get_find(value)
                        ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim/pathfinder/library/model.py", line 277, in _get_find
    raise Exception(f"Regex {value.regex} not found in {original_res}")
Exception: Regex \d+ not found in N/A

Returning default value in find
  warnings.warn(
slurmstepd: error: *** JOB 9500597 ON gcn4 CANCELLED AT 2025-01-20T09:46:41 DUE TO TIME LIMIT ***

JOB STATISTICS
==============
Job ID: 9500597
Cluster: snellius
User/Group: overven/overven
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 9
CPU Utilized: 10:20:30
CPU Efficiency: 11.48% of 3-18:03:09 core-walltime
Job Wall-clock time: 10:00:21
Memory Utilized: 17.93 GB
Memory Efficiency: 29.88% of 60.00 GB
