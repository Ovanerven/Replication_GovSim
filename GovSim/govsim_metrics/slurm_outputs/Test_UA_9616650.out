============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
wandb: Appending key for api.wandb.ai to your netrc file: /home/overven/.netrc
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent_universalization_alternative
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
    inject_universalization_alternative: true
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Univ_alt_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 1
debug: false

Selected template class: Llama3Chat
[2025-01-26 20:14:14,742][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:16,  5.57s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:11<00:11,  5.69s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.61s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  3.95s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.57s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_201434-8dx8ogp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-oath-487
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/8dx8ogp0
Storage name: charmed-oath-487-8dx8ogp0
[2025-01-26 20:14:43,464][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 20:14:46,834][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
Error executing job with overrides: ['experiment=pollution_baseline_concurrent_universalization_alternative', 'llm.path=/gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a', 'group_name=Univ_alt_Meta-Llama-3-8B-Instruct', 'seed=1']
Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/main.py", line 63, in main
    run_scenario_pollution(
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/pollution/run.py", line 75, in run
    agent_id, obs = env.reset()
                    ^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 293, in reset
    return self.agent_selection, self._observe(self.agent_selection)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 229, in _observe
    state = self._observe_pool(agent)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 98, in _observe_pool
    if self.cfg.inject_systemic:  # Add this block
       ^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'inject_systemic' is not in struct
    full_key: experiment.env.inject_systemic
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: - 0.024 MB of 0.024 MB uploadedwandb: \ 0.024 MB of 0.040 MB uploadedwandb: | 0.040 MB of 0.040 MB uploadedwandb: ðŸš€ View run charmed-oath-487 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/8dx8ogp0
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_201434-8dx8ogp0/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent_universalization_alternative
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
    inject_universalization_alternative: true
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Univ_alt_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 42
debug: false

Selected template class: Llama3Chat
[2025-01-26 20:14:58,850][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:07,  2.34s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.33s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.62s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.87s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_201508-rzxcyv82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-capybara-488
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/rzxcyv82
Storage name: glorious-capybara-488-rzxcyv82
[2025-01-26 20:15:16,235][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 20:15:17,957][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
Error executing job with overrides: ['experiment=pollution_baseline_concurrent_universalization_alternative', 'llm.path=/gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a', 'group_name=Univ_alt_Meta-Llama-3-8B-Instruct', 'seed=42']
Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/main.py", line 63, in main
    run_scenario_pollution(
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/pollution/run.py", line 75, in run
    agent_id, obs = env.reset()
                    ^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 293, in reset
    return self.agent_selection, self._observe(self.agent_selection)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 229, in _observe
    state = self._observe_pool(agent)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 98, in _observe_pool
    if self.cfg.inject_systemic:  # Add this block
       ^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'inject_systemic' is not in struct
    full_key: experiment.env.inject_systemic
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: ðŸš€ View run glorious-capybara-488 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/rzxcyv82
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_201508-rzxcyv82/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent_universalization_alternative
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
    inject_universalization_alternative: true
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Univ_alt_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 100
debug: false

Selected template class: Llama3Chat
[2025-01-26 20:15:31,380][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:07,  2.34s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.34s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.63s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.88s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_201540-27oe8v1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-monkey-489
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/27oe8v1j
Storage name: dainty-monkey-489-27oe8v1j
[2025-01-26 20:15:48,748][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 20:15:50,427][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
Error executing job with overrides: ['experiment=pollution_baseline_concurrent_universalization_alternative', 'llm.path=/gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a', 'group_name=Univ_alt_Meta-Llama-3-8B-Instruct', 'seed=100']
Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/main.py", line 63, in main
    run_scenario_pollution(
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/pollution/run.py", line 75, in run
    agent_id, obs = env.reset()
                    ^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 293, in reset
    return self.agent_selection, self._observe(self.agent_selection)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 229, in _observe
    state = self._observe_pool(agent)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 98, in _observe_pool
    if self.cfg.inject_systemic:  # Add this block
       ^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'inject_systemic' is not in struct
    full_key: experiment.env.inject_systemic
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: - 0.024 MB of 0.024 MB uploadedwandb: \ 0.024 MB of 0.040 MB uploadedwandb: | 0.040 MB of 0.040 MB uploadedwandb: ðŸš€ View run dainty-monkey-489 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/27oe8v1j
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_201540-27oe8v1j/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent_universalization_alternative
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_scenario_dynamic: false
    perturbations: []
    inject_universalization_alternative: true
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Univ_alt_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 150
debug: false

Selected template class: Llama3Chat
[2025-01-26 20:16:02,917][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:07,  2.35s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.34s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:06<00:02,  2.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.63s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.89s/it]
wandb: Currently logged in as: oliver-van-erven (oliver-van-erven-university-of-amsterdam). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /gpfs/home2/overven/GovSim_v2/wandb/run-20250126_201612-zlryok3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-elevator-490
wandb: â­ï¸ View project at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS
wandb: ðŸš€ View run at https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/zlryok3a
Storage name: serene-elevator-490-zlryok3a
[2025-01-26 20:16:20,244][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: mixedbread-ai/mxbai-embed-large-v1
[2025-01-26 20:16:21,899][sentence_transformers.SentenceTransformer][INFO] - 2 prompts are loaded, with the keys: ['query', 'passage']
Error executing job with overrides: ['experiment=pollution_baseline_concurrent_universalization_alternative', 'llm.path=/gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a', 'group_name=Univ_alt_Meta-Llama-3-8B-Instruct', 'seed=150']
Traceback (most recent call last):
  File "/gpfs/home2/overven/GovSim_v2/simulation/main.py", line 63, in main
    run_scenario_pollution(
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/pollution/run.py", line 75, in run
    agent_id, obs = env.reset()
                    ^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 293, in reset
    return self.agent_selection, self._observe(self.agent_selection)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 229, in _observe
    state = self._observe_pool(agent)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/overven/GovSim_v2/simulation/scenarios/common/environment/concurrent_env.py", line 98, in _observe_pool
    if self.cfg.inject_systemic:  # Add this block
       ^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'inject_systemic' is not in struct
    full_key: experiment.env.inject_systemic
    object_type=dict

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: - 0.025 MB of 0.025 MB uploadedwandb: \ 0.025 MB of 0.041 MB uploadedwandb: | 0.041 MB of 0.041 MB uploadedwandb: ðŸš€ View run serene-elevator-490 at: https://wandb.ai/oliver-van-erven-university-of-amsterdam/EMS/runs/zlryok3a
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250126_201612-zlryok3a/logs
/gpfs/home2/overven/GovSim_v2/simulation/main.py:87: UserWarning: register_resolver() is deprecated.
See https://github.com/omry/omegaconf/issues/426 for migration instructions.

  OmegaConf.register_resolver("uuid", lambda: f"run_{uuid.uuid4()}")
/home/overven/.local/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
experiment:
  personas:
    persona_0:
      name: John
      goals: ''
    persona_1:
      name: Kate
      goals: ''
    persona_2:
      name: Jack
      goals: ''
    persona_3:
      name: Emma
      goals: ''
    persona_4:
      name: Luke
      goals: ''
    num: 5
  name: pollution_${code_version}/${group_name}
  scenario: pollution
  env:
    name: pollution_baseline_concurrent_universalization_alternative
    class_name: pollution_perturbation_concurrent_env
    max_num_rounds: 12
    initial_resource_in_pool: 100
    poupulation_change_after_round: double_100_cap
    observation_other_agents_harvesting: true
    language_nature: unconstrained
    num_agents: 5
    harvesting_order: concurrent
    assign_resource_strategy: stochastic
    inject_universalization: false
    inject_systemic: false
    inject_veilofignorance: false
    inject_scenario_dynamic: false
    inject_universalization_alternative: true
    inject_distill: false
    perturbations: []
  agent:
    agent_package: persona_v3
    system_prompt: v3
    cot_prompt: think_step_by_step
    name: LLM=${llm.path}-S=${experiment.agent.act.harvest_strategy}-Up=${experiment.agent.act.universalization_prompt}-Id=${experiment.agent.act.consider_identity_persona}-T=${llm.temperature}-${llm.top_p}
    act:
      universalization_prompt: false
      harvest_strategy: one_step
      consider_identity_persona: true
    converse:
      inject_resource_observation: ${experiment.env.observation_other_agents_harvesting}
      inject_resource_observation_strategy: manager
      max_conversation_steps: 10
      prompt_utterance: one_shot
    store:
      expiration_delta:
        days: 63
code_version: v6.4
group_name: Univ_alt_Meta-Llama-3-8B-Instruct
llm:
  path: /gpfs/home2/overven/.cache/huggingface/hub/meta-llama--Meta-Llama-3-8B-Instruct/snapshots/5f0b02c75b57c5855da9ae460ce51323ea669d8a
  backend: transformers
  is_api: false
  render: false
  temperature: 0.0
  top_p: 1.0
seed: 200
debug: false

Selected template class: Llama3Chat
[2025-01-26 20:16:34,405][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]slurmstepd: error: *** JOB 9616650 ON gcn26 CANCELLED AT 2025-01-26T20:16:36 ***

JOB STATISTICS
==============
Job ID: 9616650
Cluster: snellius
User/Group: overven/overven
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:02:05
CPU Efficiency: 4.06% of 00:51:18 core-walltime
Job Wall-clock time: 00:02:51
Memory Utilized: 2.26 GB
Memory Efficiency: 1.88% of 120.00 GB
